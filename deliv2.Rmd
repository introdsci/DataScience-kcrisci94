---
title: "p02 Model Planning and Building"
author: "Kaleb Crisci"
date: "November 21, 2019"
output: 
   html_document: 
     theme: cerulean
     df_print: paged
---
**This page has been revised. To view revision, [`Click here`](https://introdsci.github.io/DataScience-kcrisci94/deliv2_revised)

[`Index`](https://introdsci.github.io/DataScience-kcrisci94/index)
[`DELIVERABLE 1`](https://introdsci.github.io/DataScience-kcrisci94/deliv1)
[`DELIVERABLE 3`](https://introdsci.github.io/DataScience-kcrisci94/deliv3)


```{r message=FALSE, error=FALSE, warning=FALSE, results='hide'}
include <- function(library_name){
  if( !(library_name %in% installed.packages()) )
    install.packages(library_name) 
  library(library_name, character.only=TRUE)
}
```

## $\color{red}{\text{Introduction}}$ 
....
.....
.......
In the previous deliverable, we discovered that the amount of harmful molecules in the atmosphere in California has actually been decreasing over the last 15 years. We now want to get a more in-depth idea of the major causes of pollution. The goal of this deliverable is to determine if human population has any effect on the amount of air pollution in a given area.
To get started, we'll first load in our progress from Phase 1. 

```{r message=FALSE, error=FALSE, warning=FALSE, results='hide'}
include("tidyverse")
include("knitr")
include("caret")
purl("deliv1.Rmd", output = "part1.r")
source("part1.r")
```

## $\color{red}{\text{Source Analysis}}$

We then read in data from our secondary source. This source we will use is from an online database query for county populations in California from 2010 to 2018. This data is from https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?src=bkmk. Because this data is from the United States Census Bureau, a common source for datasets, I believe this data is credible. 

```{r results = "hide", message=FALSE}
new_data <- read_csv("./PEP_2018_PEPANNRES_with_ann.csv")  #read in data
```


## $\color{red}{\text{Cleaning Data}}$  

This dataset's first row is an extra header row that we will not be using, so we can remove it.

```{r}
head(new_data) #view data
new_data <- new_data[-1,]  #remove the first row
head(new_data) #view data
```

We also observe that there are 2 different columns representing geographical ID, and that the 2nd column **GEO.id2** is simply a shorter representation of the 1st column, so we don't need the first column. 

```{r}
#select all columns to be used
new_data <- new_data %>% select("GEO.id2", "GEO.display-label", "respop72010", "respop72011", "respop72012", "respop72013", "respop72014", "respop72015", "respop72016", "respop72017", "respop72018")
```

The next step is to change the names of the columns so that they are easier to understand.

```{r}
#rename columns
colnames(new_data)[colnames(new_data)=="GEO.id2"] <- "GEO_ID" #Geographical ID
colnames(new_data)[colnames(new_data)=="GEO.display-label"] <- "County" 
colnames(new_data)[colnames(new_data)=="respop72010"] <- "2010" 
colnames(new_data)[colnames(new_data)=="respop72011"] <- "2011" 
colnames(new_data)[colnames(new_data)=="respop72012"] <- "2012" 
colnames(new_data)[colnames(new_data)=="respop72013"] <- "2013" 
colnames(new_data)[colnames(new_data)=="respop72014"] <- "2014" 
colnames(new_data)[colnames(new_data)=="respop72015"] <- "2015" 
colnames(new_data)[colnames(new_data)=="respop72016"] <- "2016" 
colnames(new_data)[colnames(new_data)=="respop72017"] <- "2017" 
colnames(new_data)[colnames(new_data)=="respop72018"] <- "2018" 
colnames(new_data)
```

Now that we have all our columns named properly, we notice that the last 9 columns are all representing a common variable: year. We can use the gather function to tidy this part of the table.
```{r}
#group all the year columns into a single column and put the data values into a new column
new_data <- gather(new_data, key = "Year", value = "Population", "2010":"2018", convert = FALSE, factor_key = FALSE)
head(new_data)
```

Since all the counties in this table are located within California, that makes " County, California" irrelevant in the **County** column. Using **sapply()** and regular expressions, we can remove the " County, California" part of each description of the county.
```{r}
#0 or many characters before ' County' and 0 or many characters after that.
pattern <- "(.*) County.*"       
#function to shorten County column
new_data$County <- sapply(new_data$County, function(County){
  return(gsub(pattern, "\\1", County)) #replace with part of pattern in ()
})
head(new_data)
```

Finally, the last step to cleaning this data is to make sure that each column is being represented as the correct type. Because **GEO_ID** is representative of a specific location, it should be considered a factor. **County** is already represented as a character, so that is good. **Population** needs to be changed from a character to an integer. **Year** needs to be changed to a double to match the type from the **data** tibble. 
```{r}
new_data$GEO_ID <- as.factor(new_data$GEO_ID)
new_data$Population <- as.integer(new_data$Population)
new_data$Year <- as.double(new_data$Year)
```

# $\color{red}{\text{Models}}$

Now that we have our 2 sources of data, we can add the new source to our previous data, and see if there are any correllations that can be observed.
```{r}
new_data1 <- inner_join(data, new_data, by=c("County", "Year"))
```

Now that all the populations for those counties have been added to the table, we can create a model to determine how much effect **Population** has on harmful molecules in the air.

```{r}
set.seed(385) #this is the number to start with for random number generator

sample_selection <- createDataPartition(new_data1$Concentration, p = 0.70, list = FALSE) # p to tell 70% split

train <- new_data1[sample_selection,]
test <- new_data1[-sample_selection,]

train_model <- lm(Concentration ~ SITE_ID + Year + WEEK + DATEON + DATEOFF + Molecule + County + Population, data=train)
summary(train_model)

```

As we can see from the above model, we have a bunch of variables that are not good predictors of the Concentration level of a molecule. We can refine our model by removing these insignificant variables.
```{r}
train_model <- lm(Concentration ~ Year + WEEK + DATEON + Molecule + Population, data=train)
summary(train_model)
```


Based on these results, we can see that the Molecule, Year, Week, Date on, and population are all significant in predicting the concentration level of harmful particles in the air. The p-value is much lower than the cutoff of .05, suggesting that our model is statistically significant. However, the R squared value is fairly small, suggesting that only 34% of variation can be explained by our model.  

# $\color{red}{\text{Testing}}$

We can now use this model to help us make preditions about the concentration of harmful molecules in the air. We can use the **R2** function to calculate the R squared value, or the square of the correllation. This will always be a value between 0 and 1. The closer it it is to 1, the higher the amount of correllation. Because our R squared predicition is so low, we can conclude that we need more information in order to make an accurate prediction.

```{r}
predictions <- train_model %>% predict(test)
R2(predictions, as.numeric(test$Concentration))
```

We can also use the **MAE** function to determine the amount of error that our model gives us from predicted values to actual values. For this, the closer the result is to 0, the better our model works. 
```{r}
MAE(test$Concentration, predictions)
```

# $\color{red}{\text{Visualizations}}$

In order to show that population is a good predictor of the concentration of harmful particles, we can make a few plots. This first plot shows how population affects the concentration of just SO2.
```{r}

s02 <- new_data1 %>% filter(Molecule == "SO2")
ggplot() + geom_point(data = s02, mapping = aes(x = Population, y = Concentration))
```

This 2nd plot shows how population effects the concentration of NO4.
```{r}
NH4 <- new_data1 %>% filter(Molecule == "NH4")
ggplot() + geom_point(data = NH4, mapping = aes(x = Population, y = Concentration))
```

This 3rd plot shows how population effects the concentration of HNO3.
```{r}
HNO3 <- new_data1 %>% filter(Molecule == "HNO3")
ggplot() + geom_point(data = HNO3, mapping = aes(x = Population, y = Concentration))
```


Based on these plots, it is difficult to see that population is a significant predictor of the concentration level of harmful particles. We can conclude that this is caused either by limitations in our model (described in phase 3), or that population needs other variables to help make an accurate prediction of the concentration of harmful molecules.

[`Index`](https://introdsci.github.io/DataScience-kcrisci94/index)
[`DELIVERABLE 1`](https://introdsci.github.io/DataScience-kcrisci94/deliv1)
[`DELIVERABLE 2 REVISED`](https://introdsci.github.io/DataScience-kcrisci94/deliv2_revised)
[`DELIVERABLE 3`](https://introdsci.github.io/DataScience-kcrisci94/deliv3)

